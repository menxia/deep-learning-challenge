{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple dynamic seq2seq with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This introduction covers building seq2seq using dynamic unrolling with TF.\n",
    "TensorFlow has its own implementation of (seq2seq)[https://www.tensorflow.org/tutorials/seq2seq/]. However it uses static unrolling.\n",
    "\n",
    "**Static unrolling** involves construction of computation graph with a fixed sequence of time step. One solution for handling sequences of varying lengths is to create multiple graphs with different time lengths and separate the dataset into this buckets.\n",
    "\n",
    "\n",
    "**Dynamic unrolling** instead uses control flow ops to process sequence step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [[5, 7, 8], [6, 3], [3], [1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataâ€˜s layout is [max_time, batch_size], called time-major."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch(inputs, max_sequence_length = None):\n",
    "    seq_len = [len(seq) for seq in inputs]\n",
    "    batch_size = len(inputs)\n",
    "    \n",
    "    if max_sequence_length is None:\n",
    "        max_sequence_length = max(seq_len)\n",
    "    inputs_batch = np.zeros([max_sequence_length, batch_size], dtype = np.int32)\n",
    "    \n",
    "    for i, seq in enumerate(inputs):\n",
    "        for j, element in enumerate(seq):\n",
    "            inputs_batch[j, i] = element\n",
    "    return inputs_batch, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xt, xlen = batch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 6, 3, 1],\n",
       "       [7, 3, 0, 0],\n",
       "       [8, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shape = [max_time, batch_size]\n",
    "encoder_inputs = tf.placeholder(shape = (None, None), dtype = tf.int32, name='encoder_inputs')\n",
    "decoder_target = tf.placeholder(shape = (None, None), dtype = tf.int32, name='decoder_target')\n",
    "decoder_inputs = tf.placeholder(shape = (None, None), dtype=tf.int32, name='decoder_inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype = tf.float32)\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n",
    "_, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, encoder_inputs_embedded, dtype = tf.float32,  time_major = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow LSTM implementation stores state as a tuple of tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 20) dtype=float32>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\n",
    "\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    decoder_cell, decoder_inputs_embedded,\n",
    "    initial_state=encoder_final_state,\n",
    "    dtype=tf.float32, time_major=True, scope=\"plain_decoder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'fully_connected/Reshape_1:0' shape=(?, ?, 10) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_logits = tf.contrib.layers.linear(decoder_outputs, vocab_size)\n",
    "decoder_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_target, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test forward pass\n",
    "When building a Graph, TF will throw errors when static shapes are not matching. However, mismatches between dynamic shapes are often only discovered when we try to run something through the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_encoded:\n",
      "[[6 3 9]\n",
      " [0 4 8]\n",
      " [0 0 7]]\n",
      "decoder inputs:\n",
      "[[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "decoder predictions:\n",
      "[[8 2 9]\n",
      " [8 8 0]\n",
      " [7 7 7]\n",
      " [7 7 7]]\n"
     ]
    }
   ],
   "source": [
    "batch_ = [[6], [3, 4], [9, 8, 7]]\n",
    "\n",
    "batch_, batch_length_ = batch(batch_)\n",
    "print('batch_encoded:\\n' + str(batch_))\n",
    "\n",
    "din_, dlen_ = batch(np.ones(shape=(3, 1), dtype=np.int32),\n",
    "                            max_sequence_length=4)\n",
    "print('decoder inputs:\\n' + str(din_))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    pred_ = sess.run(decoder_prediction,\n",
    "    feed_dict={\n",
    "        encoder_inputs: batch_,\n",
    "        decoder_inputs: din_,\n",
    "    })\n",
    "print('decoder predictions:\\n' + str(pred_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "Train our model to memorize and reproduce input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_sequences(length_from, length_to,\n",
    "                     vocab_lower, vocab_upper,\n",
    "                     batch_size):\n",
    "    \"\"\" Generates batches of random integer sequences,\n",
    "        sequence length in [length_from, length_to],\n",
    "        vocabulary in [vocab_lower, vocab_upper]\n",
    "    \"\"\"\n",
    "    if length_from > length_to:\n",
    "            raise ValueError('length_from > length_to')\n",
    "\n",
    "    def random_length():\n",
    "        if length_from == length_to:\n",
    "            return length_from\n",
    "        return np.random.randint(length_from, length_to + 1)\n",
    "    \n",
    "    while True:\n",
    "        yield [\n",
    "            np.random.randint(low=vocab_lower,\n",
    "                              high=vocab_upper,\n",
    "                              size=random_length()).tolist()\n",
    "            for _ in range(batch_size)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of the batch:\n",
      "[9, 5, 8, 5, 8, 2]\n",
      "[9, 5, 7, 6, 3]\n",
      "[9, 7, 8, 8, 4]\n",
      "[6, 4, 6]\n",
      "[6, 5, 6, 2, 6, 6]\n",
      "[8, 9, 7, 5, 4, 8, 9]\n",
      "[3, 9, 9, 2]\n",
      "[3, 7, 8, 7, 4, 9]\n",
      "[3, 4, 9, 6, 8, 4]\n",
      "[5, 6, 3, 9, 4, 7, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "batches = random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('head of the batch:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    bat = next(batches)\n",
    "    encoder_inputs_, _ = batch(bat)\n",
    "    decoder_targets_, _ = batch(\n",
    "        [(sequence) + [EOS] for sequence in bat]\n",
    "    )\n",
    "    decoder_inputs_, _ = batch(\n",
    "        [[EOS] + (sequence) for sequence in bat]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        decoder_inputs: decoder_inputs_,\n",
    "        decoder_target: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.3261539936065674\n",
      "  sample 1:\n",
      "    input     > [6 7 3 7 2 3 0 0]\n",
      "    predicted > [9 9 4 0 0 4 0 7 3]\n",
      "  sample 2:\n",
      "    input     > [8 4 8 0 0 0 0 0]\n",
      "    predicted > [9 9 9 0 3 3 3 3 3]\n",
      "  sample 3:\n",
      "    input     > [8 2 9 9 3 6 0 0]\n",
      "    predicted > [9 0 0 6 6 0 9 9 3]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.3551306128501892\n",
      "  sample 1:\n",
      "    input     > [5 4 5 4 9 3 4 2]\n",
      "    predicted > [5 4 5 4 9 4 4 2 1]\n",
      "  sample 2:\n",
      "    input     > [9 3 2 8 5 2 9 0]\n",
      "    predicted > [9 3 2 5 5 2 9 1 0]\n",
      "  sample 3:\n",
      "    input     > [5 4 6 6 2 6 0 0]\n",
      "    predicted > [5 6 6 6 2 6 1 0 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.18548312783241272\n",
      "  sample 1:\n",
      "    input     > [8 9 7 7 7 3 0 0]\n",
      "    predicted > [8 7 7 7 7 3 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 3 4 6 0 0 0 0]\n",
      "    predicted > [4 3 4 6 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [5 7 7 6 2 7 0 0]\n",
      "    predicted > [7 7 7 6 2 7 1 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.12836958467960358\n",
      "  sample 1:\n",
      "    input     > [6 6 8 5 4 9 5 0]\n",
      "    predicted > [6 6 8 5 9 9 5 1 0]\n",
      "  sample 2:\n",
      "    input     > [9 4 2 4 4 9 9 0]\n",
      "    predicted > [9 4 4 4 4 9 9 1 0]\n",
      "  sample 3:\n",
      "    input     > [9 7 2 3 8 7 4 8]\n",
      "    predicted > [9 7 2 3 8 7 4 6 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "max_batches = 3001\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    try:\n",
    "        for bat in range(max_batches):\n",
    "            fd = next_feed()\n",
    "            _, l = sess.run([train_op, loss], fd)\n",
    "            loss_track.append(l)\n",
    "\n",
    "            if bat == 0 or bat % batches_in_epoch == 0:\n",
    "                print('batch {}'.format(bat))\n",
    "                print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "                predict_ = sess.run(decoder_prediction, fd)\n",
    "                for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                    print('  sample {}:'.format(i + 1))\n",
    "                    print('    input     > {}'.format(inp))\n",
    "                    print('    predicted > {}'.format(pred))\n",
    "                    if i >= 2:\n",
    "                        break\n",
    "                print()\n",
    "    except KeyboardInterrupt:\n",
    "        print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.1269 after 300100 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114caaba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dlnd-tf-lab]",
   "language": "python",
   "name": "conda-env-dlnd-tf-lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
